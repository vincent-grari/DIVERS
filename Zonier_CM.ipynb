{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Bienvenue dans Colaboratory",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vincent-grari/DIVERS/blob/main/Zonier_CM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dKqhmXWC3YCk",
        "outputId": "b7ba5d96-9a26-424c-c9a8-a23b7b7b6d92"
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import sklearn as sk\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, MaxAbsScaler\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.tree import DecisionTreeRegressor \n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "import sys\n",
        "print(sys.argv)\n",
        "import os\n",
        "import urllib\n",
        "import os.path\n",
        "import sklearn.preprocessing as preprocessing\n",
        "from collections import namedtuple\n",
        "import pandas as pd"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py', '-f', '/root/.local/share/jupyter/runtime/kernel-ac9be87b-ceb6-4c24-bd55-b485479fedf2.json']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e1ShaOon3mKi",
        "outputId": "7b751ae4-aa3d-467b-f15e-27b08448d246"
      },
      "source": [
        "pip install --upgrade scikit-learn"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: scikit-learn in /usr/local/lib/python3.7/dist-packages (0.24.2)\n",
            "Requirement already satisfied, skipping upgrade: scipy>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.4.1)\n",
            "Requirement already satisfied, skipping upgrade: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (2.1.0)\n",
            "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.0.1)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.19.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BTZ9sqfK25Xu",
        "outputId": "5905b4fe-3e32-4cf4-c8da-6f903f812f4f"
      },
      "source": [
        "!wget \"http://grarivincent.com/research/baseINSEE.csv\""
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-06-21 12:06:23--  http://grarivincent.com/research/baseINSEE.csv\n",
            "Resolving grarivincent.com (grarivincent.com)... 217.160.0.183, 2001:8d8:100f:f000::2ce\n",
            "Connecting to grarivincent.com (grarivincent.com)|217.160.0.183|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5107089 (4.9M) [text/csv]\n",
            "Saving to: ‘baseINSEE.csv’\n",
            "\n",
            "baseINSEE.csv       100%[===================>]   4.87M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2021-06-21 12:06:23 (34.7 MB/s) - ‘baseINSEE.csv’ saved [5107089/5107089]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VHwbXPei7Ubh"
      },
      "source": [
        "baseINSEE = (pd.read_csv(\"baseINSEE.csv\", #names=column_names,\n",
        "                    sep=r'\\s*;\\s*', engine='python', na_values=['NA']))"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "shoz5s--ram7"
      },
      "source": [
        "baseINSEE['pol_insee_code']= baseINSEE['code_commune_INSEE']"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "801LTIAKhMoX",
        "outputId": "6a1304c3-77f5-4b66-f53e-66af942d8799"
      },
      "source": [
        "import sys, os\n",
        "sys.path.append(os.path.abspath(os.path.join('../..')))\n",
        "def load_ICU_Pricing(path):\n",
        "    #column_names = [\"CalYear\",\"Gender\",\"Type\",\"Category\",\"Occupation\",\"Age\",\"Group1\",\"Bonus\",\"Poldur\",\"Value\",\"Adind\",\"SubGroup2\",\"Group2\",\"Density\",\"Y\"]\n",
        "    #input_data = (pd.read_csv(path, #names=column_names,\n",
        "    #                           sep=r',', engine='python', keep_default_na=False, na_values=['NA']))\n",
        "    \n",
        "    path = \"http://grarivincent.com/research/db4ModelFull2.csv\"\n",
        "    input_data = (pd.read_csv(path, #names=column_names,\n",
        "                                sep=r',', engine='python', na_values=['NA']))\n",
        "    input_data=input_data.drop(columns=['Unnamed: 0'])\n",
        "    \n",
        "    base=baseINSEE\n",
        "    base = base[~base.pol_insee_code.str[:2].isin([\"2A\",\"2B\"])]\n",
        "    base[\"pol_insee_code\"] = base[\"pol_insee_code\"].astype(int)\n",
        "    base_nd =  base.drop_duplicates(subset=['pol_insee_code'])\n",
        "\n",
        "    input_data = input_data.drop_duplicates()\n",
        "    input_data = input_data[~input_data.pol_insee_code.str[:2].isin([\"2A\",\"2B\"])]\n",
        "    input_data[\"pol_insee_code\"] = input_data[\"pol_insee_code\"].astype(int)\n",
        "\n",
        "    input_data = input_data.merge(base_nd, how='inner', on=\"pol_insee_code\")\n",
        "    #input_data = input_data[input_data['claim_amount']<=5000]\n",
        "    input_data=input_data[input_data['claim_amount']!=0]\n",
        "   \n",
        "    #\n",
        "    sensitive_attribs = ['Age']\n",
        "    print(input_data.shape)\n",
        "    G0 = (input_data.iloc[:, 37:180]) #137])\n",
        "    #Z0 = pd.concat(Z0,input_data['long'])\n",
        "    G0=G0.select_dtypes([np.number])\n",
        "    G0 = G0.fillna(G0.mean())\n",
        "    G=G0\n",
        "    #Z = (Z0\n",
        "    #    .drop(columns=['\"REG\"'\n",
        "    #                   ])\n",
        "    #    .fillna('Unknown').pipe(pd.get_dummies))\n",
        "\n",
        "    y = input_data['claim_nb']\n",
        "    E  = input_data['exposure']\n",
        "    #I = input_data[\"pol_insee_code\"]\n",
        "    I = input_data[['pol_insee_code','latitude','longitude']]\n",
        "\n",
        "    # features; note that the 'target' and sentive attribute columns are dropped\n",
        "    X0 = input_data.iloc[:, 5:32]\n",
        "    \n",
        "    X = (X0\n",
        "          .drop(columns=['pol_coverage','pol_insee_code'])\n",
        "          .fillna('Unknown').pipe(pd.get_dummies))\n",
        "    INSEE = input_data.iloc[:, 36]\n",
        "    print(f\"features X: {X.shape[0]} samples, {X.shape[1]} attributes\")\n",
        "    print(f\"targets y: {y.shape[0]} samples\")\n",
        "    print(f\"sensitives E: {E.shape[0]} samples, {E.shape[0]} attributes\")\n",
        "    return X, y, G, E, I\n",
        "\n",
        "X, y, G, E, I =load_ICU_Pricing(\"http://grarivincent.com/research/db4modelfull3.csv\")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:15: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  from ipykernel import kernelapp as app\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "(11025, 151)\n",
            "features X: 11025 samples, 625 attributes\n",
            "targets y: 11025 samples\n",
            "sensitives E: 11025 samples, 11025 attributes\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a2qiI5I0n6Kd",
        "outputId": "1ce50ffa-f854-4342-cdf1-ab93f2566650"
      },
      "source": [
        "(y>0).mean()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-AdjIK01Q6tn"
      },
      "source": [
        "G= G.iloc[:, :-5]"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DU3bfJ9cmfjk"
      },
      "source": [
        "X_train, X_test, y_train, y_test, G_train, G_test, E_train, E_test, I_train, I_test  = train_test_split(X, y, G, E, I, test_size=0.2, random_state=7)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GqgJEuXeydqs"
      },
      "source": [
        "scaler = StandardScaler().fit(X_train)\n",
        "scale_df = lambda df, scaler: pd.DataFrame(scaler.transform(df), columns=df.columns, index=df.index)\n",
        "X_train = X_train.pipe(scale_df, scaler) \n",
        "X_test = X_test.pipe(scale_df, scaler)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rD04iS282HyO"
      },
      "source": [
        "scalerg = StandardScaler().fit(G_train)\n",
        "scale_df_g = lambda df, scaler: pd.DataFrame(scalerg.transform(df), columns=df.columns, index=df.index)\n",
        "G_train = G_train.pipe(scale_df_g, scaler) \n",
        "G_test = G_test.pipe(scale_df_g, scaler)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rH5_iGf7yA8S"
      },
      "source": [
        "y_traint =np.expand_dims(y_train,axis=1)\n",
        "y_testt =np.expand_dims(y_test,axis=1)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qjbpVMwZYstK"
      },
      "source": [
        "### **GLM POISSON SANS ZONIER **"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FszwwGGbYstX",
        "outputId": "2a3de6b0-e9ce-4d96-f451-868bd99e0f9d"
      },
      "source": [
        "from sklearn import linear_model\n",
        "reg = linear_model.GammaRegressor() \n",
        "reg.fit(X_train,y_train)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GammaRegressor()"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iQzFsSpy8OyW"
      },
      "source": [
        "def EDR_GAMMA(yhat, y):\n",
        "  #loss=torch.mean(torch.exp(xbeta)-y*xbeta)\n",
        "  #loss=torch.mean(yhat-y*torch.log(yhat))\n",
        "  eps=0.000000000001\n",
        "  res=1-np.mean(-np.log(y/yhat)+(y-yhat)/yhat)/np.mean(-np.log(y/np.mean(y))+(y-np.mean(y))/np.mean(y))\n",
        "  return res\n",
        "\n",
        "def gini_coefficient(x):\n",
        "    \"\"\"Compute Gini coefficient of array of values\"\"\"\n",
        "    diffsum = 0\n",
        "    for i, xi in enumerate(x[:-1], 1):\n",
        "        diffsum += np.sum(np.abs(xi - x[i:]))\n",
        "    return diffsum / (len(x)**2 * np.mean(x))"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f_qTcnWhYstX",
        "outputId": "16024824-f1e5-4cef-821e-8bbecbb59b4a"
      },
      "source": [
        "print(\" GINI Poi without zonier via Reg : \", gini_coefficient(reg.predict(X_train)))\n",
        "print(\" GINI Poi without zonier via Reg : \", gini_coefficient(reg.predict(X_test)))\n",
        "print(\" EDR POIS Poi without zonier via Reg : \", EDR_GAMMA(reg.predict(X_train),y_train))\n",
        "print(\" EDR POIS Poi without zonier via Reg : \", EDR_GAMMA(reg.predict(X_test),y_test))\n",
        "MSE_Poi_tr =  ((reg.predict(X_train)-y_train)**2).mean()\n",
        "MSE_Poi_test =  ((reg.predict(X_test)-y_test)**2).mean()\n",
        "print(\" MSE Poi without zonier via Reg : \", MSE_Poi_tr)\n",
        "print(\" MSE Poi without zonier via Reg : \", MSE_Poi_test)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " GINI Poi without zonier via Reg :  0.020862612402880655\n",
            " GINI Poi without zonier via Reg :  0.020115198778913178\n",
            " EDR POIS Poi without zonier via Reg :  0.07828269788033726\n",
            " EDR POIS Poi without zonier via Reg :  -0.012907245669822265\n",
            " MSE Poi without zonier via Reg :  0.11435882930640887\n",
            " MSE Poi without zonier via Reg :  0.10882255645636843\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v7ZmcTQ3fb9p",
        "outputId": "100d54a6-69de-4b1f-c936-b85e7fa5bc26",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "reg.score(X_train,y_train)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.07828269788052533"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zeQCV_zL76p2"
      },
      "source": [
        "PRICING NN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J1LULlC-78cq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d60b8d31-6b0c-47a5-bfe6-19f97ac136dd"
      },
      "source": [
        "!wget \"https://raw.githubusercontent.com/vincent-grari/DIVERS/main/pricing_nn.py\""
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-06-21 12:24:08--  https://raw.githubusercontent.com/vincent-grari/DIVERS/main/pricing_nn.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4768 (4.7K) [text/plain]\n",
            "Saving to: ‘pricing_nn.py’\n",
            "\n",
            "pricing_nn.py       100%[===================>]   4.66K  --.-KB/s    in 0s      \n",
            "\n",
            "2021-06-21 12:24:08 (69.5 MB/s) - ‘pricing_nn.py’ saved [4768/4768]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2HWfdsLD4FOc"
      },
      "source": [
        "from pricing_nn import Pricing_NN"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KbYKiFZejvkd"
      },
      "source": [
        "from tqdm import tqdm \n",
        "from sklearn.utils import shuffle\n",
        "import numpy as np\n",
        "import torch \n",
        "import torch.nn as nn \n",
        "import torch.nn.functional as F \n",
        "from torch.autograd import Variable\n",
        "\n",
        "import torch \n",
        "import torch.nn as nn \n",
        "import torch.nn.functional as F \n",
        "from tqdm import tqdm \n",
        "\n",
        "class Pricing_NN(torch.nn.Module): \n",
        "\n",
        "    def __init__(self,regressor, mod_h,mod_g,lr,batch_size,p_device,nbepoch): \n",
        "        super().__init__()\n",
        "        self.lr = lr\n",
        "        self.batch_size = int(batch_size)\n",
        "        self.device = torch.device(p_device)\n",
        "        self.nbepoch = int(nbepoch)\n",
        "        self.model_h = mod_h()\n",
        "        self.model_g = mod_g()\n",
        "        if regressor == 'poisson': \n",
        "          # Use Adam to fit the model \n",
        "          self.criterion = self.Poisson_Loss\n",
        "        elif regressor == 'gamma': \n",
        "          self.criterion = self.Gamma_Loss\n",
        "        else: \n",
        "          self.criterion = self.Gamma_Loss\n",
        "    def forward(self, x): \n",
        "        out = self.linear(x) \n",
        "        return out \n",
        "\n",
        "    def predict(self, X_train,G_train,E_train): \n",
        "        e_var = torch.FloatTensor(np.expand_dims(E_train,axis = 1)).to(self.device)\n",
        "        x_var = Variable(torch.FloatTensor(X_train.values)).to(self.device)\n",
        "        g_out = self.predict_g(G_train)\n",
        "        yhat= self.model_h(torch.cat((x_var,g_out),1),e_var)\n",
        "        return yhat\n",
        "\n",
        "    def predict_g(self, G_train): \n",
        "        g_var = Variable((torch.FloatTensor(G_train.values))).to(self.device)\n",
        "        g_out = self.model_g(g_var)\n",
        "        return g_out\n",
        "\n",
        "    def Poisson_Loss(self,yhat, y):\n",
        "      #loss=torch.mean(torch.exp(xbeta)-y*xbeta)\n",
        "      loss=torch.mean(yhat-y*torch.log(yhat))\n",
        "      return loss\n",
        "    \n",
        "    def Gamma_Loss(self,yhat, y):\n",
        "      #loss = torch.mean(yhat+(y-torch.log(yhat))/torch.log(yhat))\n",
        "      loss = torch.mean(-torch.log(y/yhat)+(y-yhat)/yhat)\n",
        "      return loss  \n",
        "    \n",
        "    def EDR_POIS(self, yhat, y):\n",
        "    #loss=torch.mean(torch.exp(xbeta)-y*xbeta)\n",
        "    #loss=torch.mean(yhat-y*torch.log(yhat))\n",
        "      eps=0.000000000001\n",
        "      res=1-np.mean((y*np.log((y+eps)/yhat)-(y-yhat)))/np.mean((y*np.log((y+eps)/np.mean(y))))\n",
        "      return res\n",
        "    \n",
        "    def fit(self, X_train, y_train, G_train, E_train): \n",
        "        batch_no = len(X_train) // self.batch_size\n",
        "        ##### PREDICTOR H #####\n",
        "        #self.model_h=NN_POISS()\n",
        "        #criterion = nn.PoissonNLLLoss()\n",
        " \n",
        "        #criterion = self.Poisson_Loss\n",
        "        #, eps=1e-8) #torch.nn.MSELoss() #reduction='mean'\n",
        "        optimizer_h = torch.optim.Adam(self.model_h.parameters(), lr=self.lr)\n",
        "        self.model_h.to(self.device)\n",
        "\n",
        "        ##### PREDICTOR G #####\n",
        "        #self.model_g=NN_G()\n",
        "        #criterion = torch.nn.MSELoss() #reduction='mean'\n",
        "        optimizer_g = torch.optim.Adam(self.model_g.parameters(), lr=self.lr)\n",
        "        self.model_g.to(self.device)\n",
        "        for epoch in tqdm(range(1, self.nbepoch + 1), 'Epoch: ', leave=False):\n",
        "            x_train, ytrain, g_train, e_train = shuffle(X_train.values,np.expand_dims(y_train,axis = 1),G_train.values,np.expand_dims(E_train,axis = 1))\n",
        "            # Mini batch learning\n",
        "            for i in range(batch_no):\n",
        "                start = i * self.batch_size\n",
        "                end = start + self.batch_size\n",
        "                g_var = Variable(torch.FloatTensor(g_train[start:end])).to(self.device)\n",
        "                e_var = Variable(torch.FloatTensor(e_train[start:end])).to(self.device)\n",
        "                x_var = Variable(torch.FloatTensor(x_train[start:end])).to(self.device)\n",
        "                y_var = Variable(torch.FloatTensor(ytrain[start:end])).to(self.device)\n",
        "                # Forward + Backward + Optimize\n",
        "\n",
        "                for l in range(1):\n",
        "                  optimizer_g.zero_grad()\n",
        "                  g_out = self.model_g(g_var)\n",
        "                  ypred_var= self.model_h(torch.cat((x_var,g_out),1),e_var)\n",
        "                  #ypred_var=  model_h(x_var,e_var)\n",
        "                  #loss = F.poisson_nll_loss(ypred_var, y_var, reduction='none') \n",
        "                  #loss = torch.mean(loss)\n",
        "                  loss = self.criterion(ypred_var, y_var)\n",
        "                  loss.backward()\n",
        "                  optimizer_g.step()\n",
        "                  #print('epoch :',epoch,'loss', loss)\n",
        "        \n",
        "                optimizer_h.zero_grad()\n",
        "                g_out = self.model_g(g_var)\n",
        "                ypred_var= self.model_h(torch.cat((x_var,g_out),1),e_var)\n",
        "                #ypred_var= model_h(x_var,e_var)\n",
        "                #loss = F.poisson_nll_loss(ypred_var, y_var, reduction='none') \n",
        "                #loss = torch.mean(loss)\n",
        "                loss = self.criterion(ypred_var, y_var)\n",
        "                loss.backward()\n",
        "                optimizer_h.step()  \n",
        "                #print(loss)   \n",
        "        yhat = self.predict(X_train, G_train, E_train).cpu().data.numpy()\n",
        "        #print(yhat.shape)\n",
        "        #print(y_train.shape)\n",
        "        return print('DONE')\n"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t50DncPI8KiT"
      },
      "source": [
        "class NN_G(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(NN_G, self).__init__()\n",
        "        self.fc1 = nn.Linear(G_train.shape[1], 128)\n",
        "        self.fc2 = nn.Linear(128, 64)\n",
        "        self.fc3 = nn.Linear(64, 16)\n",
        "        self.fc4 = nn.Linear(16, 1)        \n",
        "    def forward(self, x):\n",
        "        h1 = torch.relu(self.fc1(x))\n",
        "        #x = F.dropout(x, p=0.2)\n",
        "        h2 = torch.relu(self.fc2(h1))\n",
        "        #x = F.dropout(x, p=0.2)\n",
        "        h3 = torch.relu(self.fc3(h2))\n",
        "        #x = F.dropout(x, p=0.2)\n",
        "        h4 = self.fc4(h3)\n",
        "        return h4\n",
        "\n",
        "class NN_GLM(nn.Module):    \n",
        "    def __init__(self):\n",
        "        super(NN_GLM, self).__init__()\n",
        "        self.fc1 = nn.Linear(X_train.shape[1]+1, 1)\n",
        "    def forward(self, x,exposure):\n",
        "        h1 = torch.exp(self.fc1(x))\n",
        "        #h1 = self.fc1(x)+torch.log(exposure)\n",
        "        return h1"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xSNbo1-4yA0V"
      },
      "source": [
        "P1_NN = Pricing_NN(regressor=\"gamma\",mod_h=NN_GLM,mod_g= NN_G, batch_size = 1024,nbepoch = 1000, lr = 0.0001, p_device= 'cuda')"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RrxRf5rk5JeP"
      },
      "source": [
        "from tqdm import tqdm \n",
        "from sklearn.utils import shuffle\n",
        "from torch.autograd import Variable"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "65q38I4q0j6h"
      },
      "source": [
        "P1_NN.fit(X_train, y_train, G_train, E_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2qJuBuTy0i4G"
      },
      "source": [
        "P1_NN.predict(X_train, G_train, E_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0SnC440ourzs"
      },
      "source": [
        "P1_NN.predict_g(G_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zG-S-Q7dvVNj"
      },
      "source": [
        "y_pred2= P1_NN.predict(X_train, G_train, E_train).cpu().data.numpy()\n",
        "y_pred2t= P1_NN.predict(X_test, G_test, E_test).cpu().data.numpy()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aJwiqpaWvHEh"
      },
      "source": [
        "print(\" GINI Poi without zonier via Reg : \", gini_coefficient(y_pred2))\n",
        "print(\" GINI Poi without zonier via Reg : \", gini_coefficient(y_pred2t))\n",
        "print(\" EDR POIS Poi without zonier via Reg : \", EDR_POIS(y_pred2,y_traint))\n",
        "print(\" EDR POIS Poi without zonier via Reg : \", EDR_POIS(y_pred2t,y_testt))\n",
        "print(\" MSE NN without zonier via Reg : \", np.mean((y_traint- y_pred2)**2))\n",
        "print(\" MSE NN without zonier via Reg : \", np.mean((y_testt- y_pred2t)**2))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}